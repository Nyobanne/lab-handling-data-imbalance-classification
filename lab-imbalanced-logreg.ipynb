{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxlPZ-ncsBQt"
   },
   "source": [
    "# Lab - Handling Data Imbalance in Classification Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHq_AlFksBQz"
   },
   "source": [
    "# Feature selection with p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G6hnSU7ksBQz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "#pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_columns')\n",
    "#pd.set_option('display.max_rows',None)\n",
    "#pd.set_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vaQOE4yjsBQ0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 315)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = pd.read_csv('numerical.csv')\n",
    "numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ttfY8NFosBQ1"
   },
   "outputs": [],
   "source": [
    "targets = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical= pd.read_csv('categorical.csv')\n",
    "categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look critically at the dtypes of numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a-YA9rDebhhR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCODE         int64\n",
       "AGE         float64\n",
       "INCOME        int64\n",
       "WEALTH1       int64\n",
       "HIT           int64\n",
       "MALEMILI      int64\n",
       "MALEVET       int64\n",
       "VIETVETS      int64\n",
       "WWIIVETS      int64\n",
       "LOCALGOV      int64\n",
       "STATEGOV      int64\n",
       "FEDGOV        int64\n",
       "WEALTH2       int64\n",
       "POP901        int64\n",
       "POP902        int64\n",
       "POP903        int64\n",
       "POP90C1       int64\n",
       "POP90C2       int64\n",
       "POP90C3       int64\n",
       "POP90C4       int64\n",
       "POP90C5       int64\n",
       "ETH1          int64\n",
       "ETH2          int64\n",
       "ETH3          int64\n",
       "ETH4          int64\n",
       "ETH5          int64\n",
       "ETH6          int64\n",
       "ETH7          int64\n",
       "ETH8          int64\n",
       "ETH9          int64\n",
       "ETH10         int64\n",
       "ETH11         int64\n",
       "ETH12         int64\n",
       "ETH13         int64\n",
       "ETH14         int64\n",
       "ETH15         int64\n",
       "ETH16         int64\n",
       "AGE901        int64\n",
       "AGE902        int64\n",
       "AGE903        int64\n",
       "AGE904        int64\n",
       "AGE905        int64\n",
       "AGE906        int64\n",
       "AGE907        int64\n",
       "CHIL1         int64\n",
       "CHIL2         int64\n",
       "CHIL3         int64\n",
       "AGEC1         int64\n",
       "AGEC2         int64\n",
       "AGEC3         int64\n",
       "AGEC4         int64\n",
       "AGEC5         int64\n",
       "AGEC6         int64\n",
       "AGEC7         int64\n",
       "CHILC1        int64\n",
       "CHILC2        int64\n",
       "CHILC3        int64\n",
       "CHILC4        int64\n",
       "CHILC5        int64\n",
       "HHAGE1        int64\n",
       "HHAGE2        int64\n",
       "HHAGE3        int64\n",
       "HHN1          int64\n",
       "HHN2          int64\n",
       "HHN3          int64\n",
       "HHN4          int64\n",
       "HHN5          int64\n",
       "HHN6          int64\n",
       "MARR1         int64\n",
       "MARR2         int64\n",
       "MARR3         int64\n",
       "MARR4         int64\n",
       "HHP1          int64\n",
       "HHP2          int64\n",
       "DW1           int64\n",
       "DW2           int64\n",
       "DW3           int64\n",
       "DW4           int64\n",
       "DW5           int64\n",
       "DW6           int64\n",
       "DW7           int64\n",
       "DW8           int64\n",
       "DW9           int64\n",
       "HV1           int64\n",
       "HV2           int64\n",
       "HV3           int64\n",
       "HV4           int64\n",
       "HU1           int64\n",
       "HU2           int64\n",
       "HU3           int64\n",
       "HU4           int64\n",
       "HU5           int64\n",
       "HHD1          int64\n",
       "HHD2          int64\n",
       "HHD3          int64\n",
       "HHD4          int64\n",
       "HHD5          int64\n",
       "HHD6          int64\n",
       "HHD7          int64\n",
       "HHD8          int64\n",
       "HHD9          int64\n",
       "HHD10         int64\n",
       "HHD11         int64\n",
       "HHD12         int64\n",
       "ETHC1         int64\n",
       "ETHC2         int64\n",
       "ETHC3         int64\n",
       "ETHC4         int64\n",
       "ETHC5         int64\n",
       "ETHC6         int64\n",
       "HVP1          int64\n",
       "HVP2          int64\n",
       "HVP3          int64\n",
       "HVP4          int64\n",
       "HVP5          int64\n",
       "HVP6          int64\n",
       "HUR1          int64\n",
       "HUR2          int64\n",
       "RHP1          int64\n",
       "RHP2          int64\n",
       "RHP3          int64\n",
       "RHP4          int64\n",
       "HUPA1         int64\n",
       "HUPA2         int64\n",
       "HUPA3         int64\n",
       "HUPA4         int64\n",
       "HUPA5         int64\n",
       "HUPA6         int64\n",
       "HUPA7         int64\n",
       "RP1           int64\n",
       "RP2           int64\n",
       "RP3           int64\n",
       "RP4           int64\n",
       "MSA         float64\n",
       "ADI         float64\n",
       "DMA         float64\n",
       "IC1           int64\n",
       "IC2           int64\n",
       "IC3           int64\n",
       "IC4           int64\n",
       "IC5           int64\n",
       "IC6           int64\n",
       "IC7           int64\n",
       "IC8           int64\n",
       "IC9           int64\n",
       "IC10          int64\n",
       "IC11          int64\n",
       "IC12          int64\n",
       "IC13          int64\n",
       "IC14          int64\n",
       "IC15          int64\n",
       "IC16          int64\n",
       "IC17          int64\n",
       "IC18          int64\n",
       "IC19          int64\n",
       "IC20          int64\n",
       "IC21          int64\n",
       "IC22          int64\n",
       "IC23          int64\n",
       "HHAS1         int64\n",
       "HHAS2         int64\n",
       "HHAS3         int64\n",
       "HHAS4         int64\n",
       "MC1           int64\n",
       "MC2           int64\n",
       "MC3           int64\n",
       "TPE1          int64\n",
       "TPE2          int64\n",
       "TPE3          int64\n",
       "TPE4          int64\n",
       "TPE5          int64\n",
       "TPE6          int64\n",
       "TPE7          int64\n",
       "TPE8          int64\n",
       "TPE9          int64\n",
       "PEC1          int64\n",
       "PEC2          int64\n",
       "TPE10         int64\n",
       "TPE11         int64\n",
       "TPE12         int64\n",
       "TPE13         int64\n",
       "LFC1          int64\n",
       "LFC2          int64\n",
       "LFC3          int64\n",
       "LFC4          int64\n",
       "LFC5          int64\n",
       "LFC6          int64\n",
       "LFC7          int64\n",
       "LFC8          int64\n",
       "LFC9          int64\n",
       "LFC10         int64\n",
       "OCC1          int64\n",
       "OCC2          int64\n",
       "OCC3          int64\n",
       "OCC4          int64\n",
       "OCC5          int64\n",
       "OCC6          int64\n",
       "OCC7          int64\n",
       "OCC8          int64\n",
       "OCC9          int64\n",
       "OCC10         int64\n",
       "OCC11         int64\n",
       "OCC12         int64\n",
       "OCC13         int64\n",
       "EIC1          int64\n",
       "EIC2          int64\n",
       "EIC3          int64\n",
       "EIC4          int64\n",
       "EIC5          int64\n",
       "EIC6          int64\n",
       "EIC7          int64\n",
       "EIC8          int64\n",
       "EIC9          int64\n",
       "EIC10         int64\n",
       "EIC11         int64\n",
       "EIC12         int64\n",
       "EIC13         int64\n",
       "EIC14         int64\n",
       "EIC15         int64\n",
       "EIC16         int64\n",
       "OEDC1         int64\n",
       "OEDC2         int64\n",
       "OEDC3         int64\n",
       "OEDC4         int64\n",
       "OEDC5         int64\n",
       "OEDC6         int64\n",
       "OEDC7         int64\n",
       "EC1           int64\n",
       "EC2           int64\n",
       "EC3           int64\n",
       "EC4           int64\n",
       "EC5           int64\n",
       "EC6           int64\n",
       "EC7           int64\n",
       "EC8           int64\n",
       "SEC1          int64\n",
       "SEC2          int64\n",
       "SEC3          int64\n",
       "SEC4          int64\n",
       "SEC5          int64\n",
       "AFC1          int64\n",
       "AFC2          int64\n",
       "AFC3          int64\n",
       "AFC4          int64\n",
       "AFC5          int64\n",
       "AFC6          int64\n",
       "VC1           int64\n",
       "VC2           int64\n",
       "VC3           int64\n",
       "VC4           int64\n",
       "ANC1          int64\n",
       "ANC2          int64\n",
       "ANC3          int64\n",
       "ANC4          int64\n",
       "ANC5          int64\n",
       "ANC6          int64\n",
       "ANC7          int64\n",
       "ANC8          int64\n",
       "ANC9          int64\n",
       "ANC10         int64\n",
       "ANC11         int64\n",
       "ANC12         int64\n",
       "ANC13         int64\n",
       "ANC14         int64\n",
       "ANC15         int64\n",
       "POBC1         int64\n",
       "POBC2         int64\n",
       "LSC1          int64\n",
       "LSC2          int64\n",
       "LSC3          int64\n",
       "LSC4          int64\n",
       "VOC1          int64\n",
       "VOC2          int64\n",
       "VOC3          int64\n",
       "HC1           int64\n",
       "HC2           int64\n",
       "HC3           int64\n",
       "HC4           int64\n",
       "HC5           int64\n",
       "HC6           int64\n",
       "HC7           int64\n",
       "HC8           int64\n",
       "HC9           int64\n",
       "HC10          int64\n",
       "HC11          int64\n",
       "HC12          int64\n",
       "HC13          int64\n",
       "HC14          int64\n",
       "HC15          int64\n",
       "HC16          int64\n",
       "HC17          int64\n",
       "HC18          int64\n",
       "HC19          int64\n",
       "HC20          int64\n",
       "HC21          int64\n",
       "MHUC1         int64\n",
       "MHUC2         int64\n",
       "AC1           int64\n",
       "AC2           int64\n",
       "CARDPROM      int64\n",
       "NUMPROM       int64\n",
       "CARDPM12      int64\n",
       "NUMPRM12      int64\n",
       "RAMNTALL    float64\n",
       "NGIFTALL      int64\n",
       "CARDGIFT      int64\n",
       "MINRAMNT    float64\n",
       "MAXRAMNT    float64\n",
       "LASTGIFT    float64\n",
       "TIMELAG       int64\n",
       "AVGGIFT     float64\n",
       "CONTROLN      int64\n",
       "HPHONE_D      int64\n",
       "RFA_2F        int64\n",
       "CLUSTER2      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "numerical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.dtypes\n",
    "pd.set_option('display.max_rows',9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.shape\n",
    "#categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some categorical data is integer. \n",
    "#we want to turn them to object so that we can test/train as categorical\n",
    "#BUT we have to make a logistic regression so we need all\n",
    "#categorical= categorical.astype('object')\n",
    "    #categorical.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate numerical and categorical back together again for your X dataframe.  Designate the TargetB as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "chpngcAZsBQ1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 337)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat((numerical,categorical),axis=1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K9k8SUxOsBQ2"
   },
   "outputs": [],
   "source": [
    "X = all_data\n",
    "y = targets['TARGET_B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "no need to transform y test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting test/train and numerical/categorical features\n",
    "train_num = X_train[numerical.columns]\n",
    "train_cat = X_train[categorical.columns]\n",
    "\n",
    "test_num = X_test[numerical.columns]\n",
    "test_cat = X_test[categorical.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #Scale NUM\n",
    "#Fit and transform TRAIN\n",
    "train_num_scaled = scaler.fit_transform(train_num)\n",
    "train_num_scaled = pd.DataFrame(train_num_scaled, columns=numerical.columns)\n",
    "# transform TEST\n",
    "test_num_scaled = scaler.transform(test_num)\n",
    "test_num_scaled = pd.DataFrame(test_num_scaled, columns=numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make it a function\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "def onehot_or_ordinal(data, categorical_columns, threshold=5):\n",
    "    \"\"\"\n",
    "    Encode categorical features using one-hot encoding if the number of unique values\n",
    "    is below the threshold, otherwise use ordinal encoding.\n",
    "\n",
    "    Parameters:\n",
    "    - data : pandas Dataframe\n",
    "    - categorical_columns : list of column names.\n",
    "    - threshold: int, the threshold value to decide between one-hot and ordinal encoding.\n",
    "\n",
    "    Returns:\n",
    "    - encoded_data: DataFrame, data with encoded categorical features.\n",
    "    \"\"\"\n",
    "#categorical_columns = [col for col in data.columns if data[col].dtype == 'object']\n",
    "    encoded_data = data.copy()\n",
    "\n",
    "    # Loop through categorical columns and encode them\n",
    "    for col in categorical_columns:\n",
    "        unique_values = data[col].nunique()\n",
    "        if unique_values <= threshold:\n",
    "            # Use one-hot encoding\n",
    "            onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "            encoded_values = onehot_encoder.fit_transform(data[col].values.reshape(-1, 1))\n",
    "            # Create new column names\n",
    "            new_cols = [col + '_' + str(val) for val in range(unique_values)]\n",
    "        else:\n",
    "            # Use ordinal encoding\n",
    "            ordinal_encoder = OrdinalEncoder()\n",
    "            encoded_values = ordinal_encoder.fit_transform(data[col].values.reshape(-1, 1))\n",
    "            new_cols = [col]\n",
    "        # Add encoded values to the DataFrame\n",
    "        encoded_df = pd.DataFrame(encoded_values, columns=new_cols, index=data.index)\n",
    "        encoded_data = pd.concat([encoded_data, encoded_df], axis=1)\n",
    "        # Drop the original categorical column\n",
    "        encoded_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76329, 34)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat_encoded = onehot_or_ordinal(train_cat,['STATE', 'HOMEOWNR', 'GENDER', 'RFA_2R', 'RFA_2A', 'GEOCODE2', 'DOMAIN_A'],5)\n",
    "train_cat_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19083, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat_encoded = onehot_or_ordinal(test_cat,['STATE', 'HOMEOWNR', 'GENDER', 'RFA_2R', 'RFA_2A', 'GEOCODE2', 'DOMAIN_A'],5)\n",
    "test_cat_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again re-concatenate train_num and train_cat as X_train (as well as test_num and test_cat) as X_test\n",
    "X_train = pd.concat([train_num_scaled, train_cat_encoded.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([test_num_scaled, test_cat_encoded.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "because target is binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anne-so1/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9493790284546455\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSu7pSRYbhhU"
   },
   "source": [
    "#  Imbalance\n",
    "- Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "- Each time fit the model and see how the accuracy of the model has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26355    0\n",
       "3034     1\n",
       "21143    0\n",
       "46939    0\n",
       "        ..\n",
       "61404    0\n",
       "17730    0\n",
       "28030    0\n",
       "15725    0\n",
       "Name: TARGET_B, Length: 76329, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6RGW-bk8bhhU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MALEMILI</th>\n",
       "      <th>MALEVET</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>...</th>\n",
       "      <th>GEOCODE2_1</th>\n",
       "      <th>GEOCODE2_2</th>\n",
       "      <th>GEOCODE2_3</th>\n",
       "      <th>DOMAIN_A_0</th>\n",
       "      <th>DOMAIN_A_1</th>\n",
       "      <th>DOMAIN_A_2</th>\n",
       "      <th>DOMAIN_A_3</th>\n",
       "      <th>DOMAIN_A_4</th>\n",
       "      <th>index</th>\n",
       "      <th>TARGET_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76325</th>\n",
       "      <td>76325</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76326</th>\n",
       "      <td>76326</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76327</th>\n",
       "      <td>76327</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76328</th>\n",
       "      <td>76328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76329 rows × 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     TCODE       AGE    INCOME   WEALTH1       HIT  MALEMILI  \\\n",
       "0          0  0.000028  0.845361  0.666667  1.000000  0.000000  0.010101   \n",
       "1          1  0.000000  0.624862  0.833333  0.888889  0.004149  0.000000   \n",
       "2          2  0.000014  0.624862  0.666667  1.000000  0.000000  0.010101   \n",
       "3          3  0.000000  0.536082  0.000000  1.000000  0.000000  0.000000   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "76325  76325  0.000042  0.907216  0.000000  0.222222  0.000000  0.000000   \n",
       "76326  76326  0.000389  0.432990  1.000000  0.888889  0.004149  0.000000   \n",
       "76327  76327  0.000028  0.670103  0.500000  0.000000  0.000000  0.010101   \n",
       "76328  76328  0.000000  0.453608  0.666667  1.000000  0.000000  0.000000   \n",
       "\n",
       "        MALEVET  VIETVETS  WWIIVETS  ...  GEOCODE2_1  GEOCODE2_2  GEOCODE2_3  \\\n",
       "0      0.484848  0.383838  0.313131  ...         1.0         0.0         0.0   \n",
       "1      0.202020  0.323232  0.131313  ...         0.0         0.0         0.0   \n",
       "2      0.242424  0.383838  0.242424  ...         0.0         0.0         0.0   \n",
       "3      0.626263  0.202020  0.464646  ...         0.0         1.0         0.0   \n",
       "...         ...       ...       ...  ...         ...         ...         ...   \n",
       "76325  0.262626  0.282828  0.393939  ...         0.0         0.0         0.0   \n",
       "76326  0.181818  0.595960  0.141414  ...         0.0         0.0         0.0   \n",
       "76327  0.292929  0.313131  0.333333  ...         0.0         1.0         0.0   \n",
       "76328  0.131313  0.424242  0.080808  ...         0.0         0.0         0.0   \n",
       "\n",
       "       DOMAIN_A_0  DOMAIN_A_1  DOMAIN_A_2  DOMAIN_A_3  DOMAIN_A_4  index  \\\n",
       "0             0.0         0.0         0.0         1.0         0.0  26355   \n",
       "1             0.0         0.0         0.0         1.0         0.0   3034   \n",
       "2             0.0         0.0         1.0         0.0         0.0  21143   \n",
       "3             0.0         1.0         0.0         0.0         0.0  46939   \n",
       "...           ...         ...         ...         ...         ...    ...   \n",
       "76325         0.0         0.0         0.0         0.0         1.0  61404   \n",
       "76326         0.0         0.0         1.0         0.0         0.0  17730   \n",
       "76327         0.0         1.0         0.0         0.0         0.0  28030   \n",
       "76328         0.0         0.0         1.0         0.0         0.0  15725   \n",
       "\n",
       "       TARGET_B  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "...         ...  \n",
       "76325         0  \n",
       "76326         0  \n",
       "76327         0  \n",
       "76328         0  \n",
       "\n",
       "[76329 rows x 352 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you resample only train set\n",
    "trainset = pd.concat([X_train.reset_index(), y_train.reset_index()], axis=1)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wx7sk87TsBQ3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_B\n",
       "0    0.949207\n",
       "1    0.050793\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['TARGET_B'].value_counts()/len(trainset['TARGET_B']) #imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xjFXAJ3EsBQ3"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B'] == 0] #majority\n",
    "category_1 = trainset[trainset['TARGET_B'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vtdsp7osBQ4"
   },
   "source": [
    "# undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "h11Cml2OsBQ4"
   },
   "outputs": [],
   "source": [
    "category_0_undersampled = resample(category_0,\n",
    "                                   replace=False,\n",
    "                                   n_samples = len(category_1)) # removes majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ye3GDr-osBQ4"
   },
   "outputs": [],
   "source": [
    "trainset_downsampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1E6hDb9KsBQ5"
   },
   "outputs": [],
   "source": [
    "trainset_downsampled['TARGET_B'].value_counts()\n",
    "y_train_down = trainset_downsampled['TARGET_B']\n",
    "X_train_down = trainset_downsampled.drop('TARGET_B',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit - undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_down, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mreset_index())\n\u001b[1;32m      2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test.reset_index())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl_S3buhsBQ5"
   },
   "source": [
    "# oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_-PHrFHsBQ5"
   },
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1,\n",
    "                                  replace=True,\n",
    "                                  n_samples = len(category_0)) #resample replace minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cId9ETJmsBQ5"
   },
   "outputs": [],
   "source": [
    "trainset_oversampled = pd.concat([category_0, category_1_oversampled], axis=0)\n",
    "trainset_oversampled['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWqS7mhosBQ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSXynf0zsBRA"
   },
   "source": [
    "## Model fit - oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_over = train_oversampled['TARGET_B']\n",
    "X_train_over = train_oversampled.drop('TARGET_B',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"precision: \",precision_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
